{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0277056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import missingno\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb155615",
   "metadata": {},
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172042f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataPath=\"sample_data.csv\"\n",
    "df=pd.read_csv(dataPath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc347eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingdata_df = df.columns[df.isnull().any()].tolist()\n",
    "missingno.matrix(df[missingdata_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d90164c",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60af0bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "##-1- Delete empty columns\n",
    "cols_to_delete = df.columns[df.isnull().sum()/len(df) > .90]\n",
    "df.drop(cols_to_delete, axis = 1, inplace = True)\n",
    "\n",
    "##-2- Removing redundant data\n",
    "\n",
    "corr_matrix = df.corr().abs() # Create correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool)) # Select upper triangle of correlation matrix\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)] # Find features with correlation greater than 0.95\n",
    "df.drop(to_drop, axis=1, inplace=True)# Drop features \n",
    "\n",
    "\n",
    "##--3- Replacing missing values in columns \n",
    "ind=[]\n",
    "for i,col in enumerate(df.columns):\n",
    "    if (df[col].isnull().values.any()):\n",
    "        # print(\"Missing values Found \")\n",
    "        ind.append(i)\n",
    "\n",
    "for i in ind:\n",
    "    if df[df.columns[i]].isnull().values.any():\n",
    "        df[df.columns[i]]=df[df.columns[i]].fillna(df[df.columns[i]].mean())\n",
    "#         print(\"missing value replaced\")\n",
    "\n",
    "\n",
    "##--3- Removing constant columns \n",
    "df=df.loc[:, (df!= df.iloc[0]).any()] ## removing constant columns\n",
    "\n",
    "\n",
    "##--4- Converting catagorical data to numerical  \n",
    "df[\"ref_group\"] = df[\"ref_group\"].astype('category')\n",
    "d = dict(enumerate(df[\"ref_group\"].cat.categories))\n",
    "print (d)\n",
    "df[\"ref_group\"] =df[\"ref_group\"].cat.codes\n",
    "\n",
    "\n",
    "\n",
    "# df.to_csv(\"processed_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cba530a",
   "metadata": {},
   "source": [
    "##\tVisualization of natural trend in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4cbf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.loc[:,df.columns != \"ref_group\"]\n",
    "Y=df.loc[:,df.columns == \"ref_group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90408fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "scaled_data = scaler.transform(X)\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(scaled_data)\n",
    "x_pca = pca.transform(scaled_data)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(x_pca[:,0],x_pca[:,1],c=df['ref_group'],cmap='plasma')\n",
    "plt.title(\"Overall data visualization\")\n",
    "plt.xlabel('First principal component')\n",
    "plt.ylabel('Second Principal Component')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40499d46",
   "metadata": {},
   "source": [
    "# Unsupervised clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1ecef7",
   "metadata": {},
   "source": [
    "### 1 - Elbow method for finding optimal number of clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4bedb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "K = range(1,10)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k)\n",
    "    kmeanModel.fit(df)\n",
    "    distortions.append(kmeanModel.inertia_)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479e1320",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20b74c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df=X.copy()\n",
    "\n",
    "#created scaled version of DataFrame\n",
    "scaled_df=pd.DataFrame(scaler.fit_transform(scaled_df), columns=scaled_df.columns)\n",
    "#define PCA model to use\n",
    "pca = PCA(n_components=10)\n",
    "\n",
    "#fit PCA model to data\n",
    "pca_fit = pca.fit(scaled_df)\n",
    "PC_values = np.arange(pca.n_components_) + 1\n",
    "plt.plot(PC_values, pca.explained_variance_ratio_, 'o-', linewidth=2, color='blue')\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Variance Explained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ad938b",
   "metadata": {},
   "source": [
    "### 2- K-mean Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf999428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "data = X\n",
    "y=df.loc[:, df.columns == \"ref_group\"]\n",
    "Y=y.to_numpy().flatten()\n",
    "pca = PCA(2)\n",
    " \n",
    "#Transform the data\n",
    "df1 = pca.fit_transform(data)\n",
    " \n",
    "#Import KMeans module\n",
    "from sklearn.cluster import KMeans\n",
    " \n",
    "#Initialize the class object\n",
    "i=6\n",
    "kmeans = KMeans(n_clusters= i)\n",
    " \n",
    "#predict the labels of clusters.\n",
    "label = kmeans.fit_predict(df1)\n",
    "# label= Y=y.to_numpy().flatten()\n",
    "#Getting unique labels\n",
    "u_labels = np.unique(label)\n",
    " \n",
    "for i in range(i):\n",
    "    cat = (label == i)\n",
    "    label[cat] = mode(Y[cat])[0]\n",
    "    \n",
    "acc = accuracy_score(Y, label)\n",
    "print(\"Accuracy using GMM = \", acc)    \n",
    "    \n",
    "#plotting the results:\n",
    "for i in u_labels:\n",
    "    plt.scatter(df1[label == i , 0] , df1[label == i , 1] , label = d[i])\n",
    "plt.legend(bbox_to_anchor=(100.05, 10.0), loc='upper left')\n",
    "# plt.legend()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "centroids = kmeans.cluster_centers_\n",
    "u_labels = np.unique(label)\n",
    " \n",
    "#plotting the results:\n",
    " \n",
    "for i in u_labels:\n",
    "    plt.scatter(df1[label == i , 0] , df1[label == i , 1] , label = d[i])\n",
    "plt.scatter(centroids[:,0] , centroids[:,1] , s = 10, color = 'k')\n",
    "plt.legend(loc='best', bbox_to_anchor=(0.5, 0., 0.5, 0.5))\n",
    "# plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0343464f",
   "metadata": {},
   "source": [
    "##  Semi_Supervise Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e615c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "XL=labeled_data=df.loc[df['ref_group'] != 6]  ## labelled examples\n",
    "XUL=unlabeled_data=df.loc[df['ref_group'] == 6]  ## unlabelled examples\n",
    "\n",
    "## spliting into training and test sets\n",
    "XL_train=XL.iloc[0:2414,1:]\n",
    "YL_train=XL.iloc[0:2414,0]\n",
    "\n",
    "XL_test=XL.iloc[2414:,1:]\n",
    "YL_test=XL.iloc[2414:,0]\n",
    "\n",
    "XUL_train=XUL.iloc[:,1:]\n",
    "YUL_train=XUL.iloc[:,0]\n",
    "\n",
    "## training model\n",
    "clf = svm.SVC(kernel='linear', probability=True,C=1).fit(XL_train, YL_train)\n",
    "clf.score(XL_test, YL_test)\n",
    "\n",
    "## probability of new class labels \n",
    "clp= clf.predict_proba(XUL_train)\n",
    "lab=clf.predict(XUL_train)\n",
    "dfl = pd.DataFrame(clp, columns = ['C1Prob', 'C2Prob','C3Prob','C4Prob', 'C5Prob','C6Prob']) \n",
    "dfl['lab']=lab\n",
    "dfl['actual']=YUL_train\n",
    "dfl['max']=dfl[['C1Prob', 'C2Prob','C3Prob','C4Prob', 'C5Prob','C6Prob']].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e708476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "y_pred_class=clf.predict(XL_test)\n",
    "\n",
    "cm=metrics.confusion_matrix(YL_test, y_pred_class)\n",
    "print(metrics.confusion_matrix(YL_test, y_pred_class))\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('class prediction for labelled data\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "# ax.xaxis.set_ticklabels(['False','True'])\n",
    "# ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcca076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "XL_train=XL_train.to_numpy()\n",
    "XL_train.shape\n",
    "XUL=XUL_train\n",
    "XUL=XUL.values\n",
    "nc=np.arange(.35,1,.03)\n",
    "acc=np.empty(22)\n",
    "i=0\n",
    "for k in np.nditer(nc):\n",
    "    conf_ind=dfl[\"max\"]>k\n",
    "\n",
    "    X_train1 = np.append(XL_train,XUL[conf_ind,:],axis=0)\n",
    "    y_train1 = np.append(YL_train,dfl.loc[conf_ind,['lab']])\n",
    "    clf = svm.SVC(kernel='linear', probability=True,C=1).fit(X_train1, y_train1)\n",
    "    acc[i]=  clf.score(XL_test,YL_test)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291c40d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(dfl[\"max\"])\n",
    "plt.title('Histogram of max-porbabilty of class labels')\n",
    "plt.xlabel('Max Probability belonging to a class')\n",
    "plt.ylabel('No. of examples')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc380df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x=pd.Series(acc,index=nc)\n",
    "x.plot()\n",
    "# Add title and axis names\n",
    "plt.title('Confidence vs Accuracy')\n",
    "plt.xlabel('Confidence')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ff6951",
   "metadata": {},
   "source": [
    "## Label Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78138c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clp2= clf.predict_proba(XUL)\n",
    "lab2=clf.predict(XUL)\n",
    "df2 = pd.DataFrame(clp2, columns = ['C1Prob', 'C2Prob','C3Prob','C4Prob', 'C5Prob','C6Prob']) \n",
    "df2['lab']=lab2\n",
    "\n",
    "df2['max']=df2[['C1Prob', 'C2Prob','C3Prob','C4Prob', 'C5Prob','C6Prob']].max(axis=1)\n",
    "df2.loc[df2['max'] < 0.65, 'lab'] = 6\n",
    "unlabeled_data['ref_group']=df2['lab'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41542881",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [labeled_data,unlabeled_data]\n",
    "df_new = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d96fdb9",
   "metadata": {},
   "source": [
    "## Clustering with newly labelled overall data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65133467",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_new.loc[:,df_new.columns != \"ref_group\"]\n",
    "Y=df_new.loc[:,df_new.columns == \"ref_group\"]\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "pca.fit(scaled_data)\n",
    "x_pca = pca.transform(scaled_data)\n",
    "\n",
    "label=Y\n",
    "u_labels = np.unique(label)\n",
    " \n",
    "#plotting the results:\n",
    "\n",
    "label=label.values.flatten()\n",
    "f={0:'group_A',1:'group_B',2:'group_C',3:'group_D',4:'group_E',5:'group_X',6:'new_group'}\n",
    "for i in u_labels:\n",
    "    plt.scatter(x_pca[label == i , 0] , x_pca[label == i , 1] , label = f[i])\n",
    "plt.legend()\n",
    "plt.title('Visualization of dataset after labelling of unlabelled data')\n",
    "\n",
    "plt.xlabel('First principal component of PCA')\n",
    "plt.ylabel('Second Principal Component of PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d7d76c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
